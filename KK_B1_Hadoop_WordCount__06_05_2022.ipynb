{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KK B1 Hadoop WordCount _06.05.2022",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preetamjumech/Hadoop_Practice/blob/main/KK_B1_Hadoop_WordCount__06_05_2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwjvirExIQAM"
      },
      "source": [
        "#Hadoop\n",
        "This Notebook has all the codes required to install Hadoop in the Colab VM and execute the a WordCount program using the streaming API <br>\n",
        "The mapper.py and reducer.py programs are available in the authors G-Drive / Github and are downloaded as required<br>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK5y3g-ySDmZ"
      },
      "source": [
        "##Acknowledgements\n",
        "Hadoop Installation from [Anjaly Sam's Github Repository](https://github.com/anjalysam/Hadoop) <br>\n",
        "\n",
        "To get the concept behind map-reduce see [this notebook](https://github.com/Praxis-QR/BDSN/blob/main/Basic_WordCount_Concept.ipynb) <br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9bT9M1yvyXG"
      },
      "source": [
        "# 1 Download, Install Hadoop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXFZuorwF25e"
      },
      "source": [
        "# The default JVM available at /usr/lib/jvm/java-11-openjdk-amd64/  works for Hadoop\n",
        "# But gives errors with Hive https://stackoverflow.com/questions/54037773/hive-exception-class-jdk-internal-loader-classloadersappclassloader-cannot\n",
        "# Hence this JVM needs to be installed\n",
        "!apt-get update > /dev/null\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bijZAdD_cBMK",
        "outputId": "2bc8e797-18fd-41eb-a78a-fa5ddc15b0e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# If there is an error in this cell, it is very likely that the version of hadoop has changed\n",
        "# Download the latest version of Hadoop and change the version numbers accordingly\n",
        "#wget -q https://downloads.apache.org/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz\n",
        "#!wget -q https://downloads.apache.org/hadoop/common/hadoop-3.3.2/hadoop-3.3.2.tar.gz\n",
        "!wget  https://downloads.apache.org/hadoop/common/hadoop-3.3.2/hadoop-3.3.2.tar.gz\n",
        "# Unzip it\n",
        "# the tar command with the -x flag to extract, -z to uncompress, -v for verbose output, and -f to specify that we’re extracting from a file\n",
        "!tar -xzf hadoop-3.3.2.tar.gz\n",
        "#copy  hadoop file to user/local\n",
        "!mv  hadoop-3.3.2/ /usr/local/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-06 05:36:04--  https://downloads.apache.org/hadoop/common/hadoop-3.3.2/hadoop-3.3.2.tar.gz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 88.99.95.219, 135.181.214.104, 2a01:4f8:10a:201a::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|88.99.95.219|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 638660563 (609M) [application/x-gzip]\n",
            "Saving to: ‘hadoop-3.3.2.tar.gz’\n",
            "\n",
            "hadoop-3.3.2.tar.gz 100%[===================>] 609.07M  22.7MB/s    in 27s     \n",
            "\n",
            "2022-05-06 05:36:31 (22.3 MB/s) - ‘hadoop-3.3.2.tar.gz’ saved [638660563/638660563]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pjQecX-LetK",
        "outputId": "9081aaa7-6a3a-49e7-b352-87fd0fb1b1e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls /usr/local"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin\t   cuda-10.1  cuda-11.1  _gcs_config_ops.so  lib\tsbin   xgboost\n",
            "cuda\t   cuda-11    etc\t hadoop-3.3.2\t     licensing\tshare\n",
            "cuda-10.0  cuda-11.0  games\t include\t     man\tsrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vh6Dqbbrwqpe"
      },
      "source": [
        "# 2 Set Environment Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OUc19ZtcBG5"
      },
      "source": [
        "#To find the default Java path\n",
        "#!readlink -f /usr/bin/java | sed \"s:bin/java::\"\n",
        "#!ls /usr/lib/jvm/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ez4T7Gs3RAn"
      },
      "source": [
        "#To set java path, go to /usr/local/hadoop-3.3.0/etc/hadoop/hadoop-env.sh then\n",
        "#. . . export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64/ . . .\n",
        "#we have used a simpler alternative route using os.environ - it works\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"   # default is changed\n",
        "#os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64/\"\n",
        "# make sure that the version number is as downloaded \n",
        "#os.environ[\"HADOOP_HOME\"] = \"/usr/local/hadoop-3.3.0/\"\n",
        "os.environ[\"HADOOP_HOME\"] = \"/usr/local/hadoop-3.3.2/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKOGAmCVhXZ4",
        "outputId": "57a7d04f-dc96-4b30-c31d-5a6f1dfe514f"
      },
      "source": [
        "!echo $PATH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDFgpWGLhdhl",
        "outputId": "20a1dcb4-ef89-49a1-f34d-3cf607138ee7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Add Hadoop BIN to PATH\n",
        "# Get the current_path from output of previous command\n",
        "#current_path = '/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin'\n",
        "current_path = '/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin'\n",
        "new_path = current_path+':/usr/local/hadoop-3.3.2/bin/'\n",
        "os.environ[\"PATH\"] = new_path\n",
        "!echo $PATH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin:/usr/local/hadoop-3.3.2/bin/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj00rPPZyEWZ"
      },
      "source": [
        "# 3 Test Hadoop Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zhf-zK7NcBDF",
        "outputId": "e641dd00-6dfe-4da6-9dc3-ab4ddaf626da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Running Hadoop - Test RUN, not doing anything at all\n",
        "#!/usr/local/hadoop-3.3.0/bin/hadoop\n",
        "# UNCOMMENT the following line if you want to make sure that Hadoop is alive!\n",
        "!hadoop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: hadoop [OPTIONS] SUBCOMMAND [SUBCOMMAND OPTIONS]\n",
            " or    hadoop [OPTIONS] CLASSNAME [CLASSNAME OPTIONS]\n",
            "  where CLASSNAME is a user-provided Java class\n",
            "\n",
            "  OPTIONS is none or any of:\n",
            "\n",
            "buildpaths                       attempt to add class files from build tree\n",
            "--config dir                     Hadoop config directory\n",
            "--debug                          turn on shell script debug mode\n",
            "--help                           usage information\n",
            "hostnames list[,of,host,names]   hosts to use in slave mode\n",
            "hosts filename                   list of hosts to use in slave mode\n",
            "loglevel level                   set the log4j level for this command\n",
            "workers                          turn on worker mode\n",
            "\n",
            "  SUBCOMMAND is one of:\n",
            "\n",
            "\n",
            "    Admin Commands:\n",
            "\n",
            "daemonlog     get/set the log level for each daemon\n",
            "\n",
            "    Client Commands:\n",
            "\n",
            "archive       create a Hadoop archive\n",
            "checknative   check native Hadoop and compression libraries availability\n",
            "classpath     prints the class path needed to get the Hadoop jar and the\n",
            "              required libraries\n",
            "conftest      validate configuration XML files\n",
            "credential    interact with credential providers\n",
            "distch        distributed metadata changer\n",
            "distcp        copy file or directories recursively\n",
            "dtutil        operations related to delegation tokens\n",
            "envvars       display computed Hadoop environment variables\n",
            "fs            run a generic filesystem user client\n",
            "gridmix       submit a mix of synthetic job, modeling a profiled from\n",
            "              production load\n",
            "jar <jar>     run a jar file. NOTE: please use \"yarn jar\" to launch YARN\n",
            "              applications, not this command.\n",
            "jnipath       prints the java.library.path\n",
            "kdiag         Diagnose Kerberos Problems\n",
            "kerbname      show auth_to_local principal conversion\n",
            "key           manage keys via the KeyProvider\n",
            "rumenfolder   scale a rumen input trace\n",
            "rumentrace    convert logs into a rumen trace\n",
            "s3guard       manage metadata on S3\n",
            "trace         view and modify Hadoop tracing settings\n",
            "version       print the version\n",
            "\n",
            "    Daemon Commands:\n",
            "\n",
            "kms           run KMS, the Key Management Server\n",
            "registrydns   run the registry DNS server\n",
            "\n",
            "SUBCOMMAND may print help when invoked w/o parameters or with -h.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n3I6iqjGod-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f179d9c-690c-4590-c921-cf5e31e2f02c"
      },
      "source": [
        "# Testing Hadoop with PI generating sample program, should calculate value of pi = 3.14157500000000000000\n",
        "# pi example\n",
        "#Uncomment the following line if  you want to test Hadoop with pi example\n",
        "# Final output should be : Estimated value of Pi is 3.14157500000000000000\n",
        "#!hadoop jar /usr/local/hadoop-3.3.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar pi 16 100000\n",
        "!hadoop jar /usr/local/hadoop-3.3.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.2.jar pi 16 100000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Maps  = 16\n",
            "Samples per Map = 100000\n",
            "Wrote input for Map #0\n",
            "Wrote input for Map #1\n",
            "Wrote input for Map #2\n",
            "Wrote input for Map #3\n",
            "Wrote input for Map #4\n",
            "Wrote input for Map #5\n",
            "Wrote input for Map #6\n",
            "Wrote input for Map #7\n",
            "Wrote input for Map #8\n",
            "Wrote input for Map #9\n",
            "Wrote input for Map #10\n",
            "Wrote input for Map #11\n",
            "Wrote input for Map #12\n",
            "Wrote input for Map #13\n",
            "Wrote input for Map #14\n",
            "Wrote input for Map #15\n",
            "Starting Job\n",
            "2022-05-06 05:45:51,546 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
            "2022-05-06 05:45:51,666 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
            "2022-05-06 05:45:51,666 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
            "2022-05-06 05:45:51,839 INFO input.FileInputFormat: Total input files to process : 16\n",
            "2022-05-06 05:45:51,856 INFO mapreduce.JobSubmitter: number of splits:16\n",
            "2022-05-06 05:45:52,124 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local961884597_0001\n",
            "2022-05-06 05:45:52,124 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2022-05-06 05:45:52,352 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2022-05-06 05:45:52,353 INFO mapreduce.Job: Running job: job_local961884597_0001\n",
            "2022-05-06 05:45:52,361 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2022-05-06 05:45:52,370 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-05-06 05:45:52,371 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-05-06 05:45:52,372 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
            "2022-05-06 05:45:52,439 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
            "2022-05-06 05:45:52,440 INFO mapred.LocalJobRunner: Starting task: attempt_local961884597_0001_m_000000_0\n",
            "2022-05-06 05:45:52,474 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-05-06 05:45:52,474 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-05-06 05:45:52,513 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-05-06 05:45:52,520 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1651815950606_1324761946/in/part2:0+118\n",
            "2022-05-06 05:45:52,756 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-05-06 05:45:52,756 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-05-06 05:45:52,756 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-05-06 05:45:52,757 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-05-06 05:45:52,757 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-05-06 05:45:52,765 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-05-06 05:45:52,819 INFO mapred.LocalJobRunner: \n",
            "2022-05-06 05:45:52,819 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-05-06 05:45:52,819 INFO mapred.MapTask: Spilling map output\n",
            "2022-05-06 05:45:52,820 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-05-06 05:45:52,820 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-05-06 05:45:52,828 INFO mapred.MapTask: Finished spill 0\n",
            "2022-05-06 05:45:52,851 INFO mapred.Task: Task:attempt_local961884597_0001_m_000000_0 is done. And is in the process of committing\n",
            "2022-05-06 05:45:52,855 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-05-06 05:45:52,855 INFO mapred.Task: Task 'attempt_local961884597_0001_m_000000_0' done.\n",
            "2022-05-06 05:45:52,872 INFO mapred.Task: Final Counters for attempt_local961884597_0001_m_000000_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=283466\n",
            "\t\tFILE: Number of bytes written=919686\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=258473984\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-05-06 05:45:52,872 INFO mapred.LocalJobRunner: Finishing task: attempt_local961884597_0001_m_000000_0\n",
            "2022-05-06 05:45:52,873 INFO mapred.LocalJobRunner: Starting task: attempt_local961884597_0001_m_000001_0\n",
            "2022-05-06 05:45:52,885 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-05-06 05:45:52,885 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-05-06 05:45:52,886 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-05-06 05:45:52,890 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1651815950606_1324761946/in/part9:0+118\n",
            "2022-05-06 05:45:53,068 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-05-06 05:45:53,068 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-05-06 05:45:53,068 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-05-06 05:45:53,068 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-05-06 05:45:53,068 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-05-06 05:45:53,069 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-05-06 05:45:53,091 INFO mapred.LocalJobRunner: \n",
            "2022-05-06 05:45:53,091 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-05-06 05:45:53,091 INFO mapred.MapTask: Spilling map output\n",
            "2022-05-06 05:45:53,091 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-05-06 05:45:53,091 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-05-06 05:45:53,093 INFO mapred.MapTask: Finished spill 0\n",
            "2022-05-06 05:45:53,099 INFO mapred.Task: Task:attempt_local961884597_0001_m_000001_0 is done. And is in the process of committing\n",
            "2022-05-06 05:45:53,101 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-05-06 05:45:53,101 INFO mapred.Task: Task 'attempt_local961884597_0001_m_000001_0' done.\n",
            "2022-05-06 05:45:53,102 INFO mapred.Task: Final Counters for attempt_local961884597_0001_m_000001_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=285685\n",
            "\t\tFILE: Number of bytes written=919746\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=363855872\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-05-06 05:45:53,102 INFO mapred.LocalJobRunner: Finishing task: attempt_local961884597_0001_m_000001_0\n",
            "2022-05-06 05:45:53,102 INFO mapred.LocalJobRunner: Starting task: attempt_local961884597_0001_m_000002_0\n",
            "2022-05-06 05:45:53,104 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-05-06 05:45:53,104 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-05-06 05:45:53,104 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-05-06 05:45:53,106 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1651815950606_1324761946/in/part7:0+118\n",
            "2022-05-06 05:45:53,263 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-05-06 05:45:53,264 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-05-06 05:45:53,264 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-05-06 05:45:53,264 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-05-06 05:45:53,264 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-05-06 05:45:53,265 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-05-06 05:45:53,271 INFO mapred.LocalJobRunner: \n",
            "2022-05-06 05:45:53,272 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-05-06 05:45:53,272 INFO mapred.MapTask: Spilling map output\n",
            "2022-05-06 05:45:53,272 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-05-06 05:45:53,272 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-05-06 05:45:53,274 INFO mapred.MapTask: Finished spill 0\n",
            "2022-05-06 05:45:53,276 INFO mapred.Task: Task:attempt_local961884597_0001_m_000002_0 is done. And is in the process of committing\n",
            "2022-05-06 05:45:53,278 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-05-06 05:45:53,278 INFO mapred.Task: Task 'attempt_local961884597_0001_m_000002_0' done.\n",
            "2022-05-06 05:45:53,279 INFO mapred.Task: Final Counters for attempt_local961884597_0001_m_000002_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=287904\n",
            "\t\tFILE: Number of bytes written=919806\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=469237760\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-05-06 05:45:53,279 INFO mapred.LocalJobRunner: Finishing task: attempt_local961884597_0001_m_000002_0\n",
            "2022-05-06 05:45:53,279 INFO mapred.LocalJobRunner: Starting task: attempt_local961884597_0001_m_000003_0\n",
            "2022-05-06 05:45:53,280 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-05-06 05:45:53,281 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-05-06 05:45:53,281 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-05-06 05:45:53,283 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1651815950606_1324761946/in/part10:0+118\n",
            "2022-05-06 05:45:53,360 INFO mapreduce.Job: Job job_local961884597_0001 running in uber mode : false\n",
            "2022-05-06 05:45:53,361 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2022-05-06 05:45:53,459 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-05-06 05:45:53,459 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-05-06 05:45:53,459 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-05-06 05:45:53,459 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-05-06 05:45:53,459 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-05-06 05:45:53,461 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-05-06 05:45:53,466 INFO mapred.LocalJobRunner: \n",
            "2022-05-06 05:45:53,466 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-05-06 05:45:53,466 INFO mapred.MapTask: Spilling map output\n",
            "2022-05-06 05:45:53,466 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-05-06 05:45:53,466 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-05-06 05:45:53,468 INFO mapred.MapTask: Finished spill 0\n",
            "2022-05-06 05:45:53,471 INFO mapred.Task: Task:attempt_local961884597_0001_m_000003_0 is done. And is in the process of committing\n",
            "2022-05-06 05:45:53,472 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-05-06 05:45:53,472 INFO mapred.Task: Task 'attempt_local961884597_0001_m_000003_0' done.\n",
            "2022-05-06 05:45:53,473 INFO mapred.Task: Final Counters for attempt_local961884597_0001_m_000003_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=290123\n",
            "\t\tFILE: Number of bytes written=919866\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=129\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=574619648\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-05-06 05:45:53,473 INFO mapred.LocalJobRunner: Finishing task: attempt_local961884597_0001_m_000003_0\n",
            "2022-05-06 05:45:53,473 INFO mapred.LocalJobRunner: Starting task: attempt_local961884597_0001_m_000004_0\n",
            "2022-05-06 05:45:53,478 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-05-06 05:45:53,478 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-05-06 05:45:53,478 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-05-06 05:45:53,480 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1651815950606_1324761946/in/part3:0+118\n",
            "2022-05-06 05:45:53,639 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-05-06 05:45:53,639 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-05-06 05:45:53,639 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-05-06 05:45:53,639 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-05-06 05:45:53,640 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-05-06 05:45:53,646 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-05-06 05:45:53,662 INFO mapred.LocalJobRunner: \n",
            "2022-05-06 05:45:53,662 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-05-06 05:45:53,662 INFO mapred.MapTask: Spilling map output\n",
            "2022-05-06 05:45:53,662 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-05-06 05:45:53,662 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-05-06 05:45:53,664 INFO mapred.MapTask: Finished spill 0\n",
            "2022-05-06 05:45:53,667 INFO mapred.Task: Task:attempt_local961884597_0001_m_000004_0 is done. And is in the process of committing\n",
            "2022-05-06 05:45:53,668 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-05-06 05:45:53,668 INFO mapred.Task: Task 'attempt_local961884597_0001_m_000004_0' done.\n",
            "2022-05-06 05:45:53,669 INFO mapred.Task: Final Counters for attempt_local961884597_0001_m_000004_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=291830\n",
            "\t\tFILE: Number of bytes written=919926\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=680001536\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-05-06 05:45:53,669 INFO mapred.LocalJobRunner: Finishing task: attempt_local961884597_0001_m_000004_0\n",
            "2022-05-06 05:45:53,669 INFO mapred.LocalJobRunner: Starting task: attempt_local961884597_0001_m_000005_0\n",
            "2022-05-06 05:45:53,670 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-05-06 05:45:53,670 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-05-06 05:45:53,671 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-05-06 05:45:53,672 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1651815950606_1324761946/in/part0:0+118\n",
            "2022-05-06 05:45:53,827 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-05-06 05:45:53,827 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-05-06 05:45:53,827 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-05-06 05:45:53,827 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-05-06 05:45:53,827 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-05-06 05:45:53,828 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-05-06 05:45:53,836 INFO mapred.LocalJobRunner: \n",
            "2022-05-06 05:45:53,836 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-05-06 05:45:53,836 INFO mapred.MapTask: Spilling map output\n",
            "2022-05-06 05:45:53,836 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-05-06 05:45:53,836 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-05-06 05:45:53,838 INFO mapred.MapTask: Finished spill 0\n",
            "2022-05-06 05:45:53,841 INFO mapred.Task: Task:attempt_local961884597_0001_m_000005_0 is done. And is in the process of committing\n",
            "2022-05-06 05:45:53,843 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-05-06 05:45:53,843 INFO mapred.Task: Task 'attempt_local961884597_0001_m_000005_0' done.\n",
            "2022-05-06 05:45:53,843 INFO mapred.Task: Final Counters for attempt_local961884597_0001_m_000005_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=293537\n",
            "\t\tFILE: Number of bytes written=919986\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=785383424\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-05-06 05:45:53,844 INFO mapred.LocalJobRunner: Finishing task: attempt_local961884597_0001_m_000005_0\n",
            "2022-05-06 05:45:53,844 INFO mapred.LocalJobRunner: Starting task: attempt_local961884597_0001_m_000006_0\n",
            "2022-05-06 05:45:53,850 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-05-06 05:45:53,850 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-05-06 05:45:53,850 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-05-06 05:45:53,854 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1651815950606_1324761946/in/part1:0+118\n",
            "2022-05-06 05:45:54,024 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-05-06 05:45:54,024 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-05-06 05:45:54,024 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-05-06 05:45:54,024 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-05-06 05:45:54,024 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-05-06 05:45:54,025 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-05-06 05:45:54,031 INFO mapred.LocalJobRunner: \n",
            "2022-05-06 05:45:54,031 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-05-06 05:45:54,031 INFO mapred.MapTask: Spilling map output\n",
            "2022-05-06 05:45:54,031 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-05-06 05:45:54,031 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-05-06 05:45:54,033 INFO mapred.MapTask: Finished spill 0\n",
            "2022-05-06 05:45:54,035 INFO mapred.Task: Task:attempt_local961884597_0001_m_000006_0 is done. And is in the process of committing\n",
            "2022-05-06 05:45:54,038 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-05-06 05:45:54,039 INFO mapred.Task: Task 'attempt_local961884597_0001_m_000006_0' done.\n",
            "2022-05-06 05:45:54,039 INFO mapred.Task: Final Counters for attempt_local961884597_0001_m_000006_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=295244\n",
            "\t\tFILE: Number of bytes written=920046\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=890765312\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-05-06 05:45:54,039 INFO mapred.LocalJobRunner: Finishing task: attempt_local961884597_0001_m_000006_0\n",
            "2022-05-06 05:45:54,039 INFO mapred.LocalJobRunner: Starting task: attempt_local961884597_0001_m_000007_0\n",
            "2022-05-06 05:45:54,043 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-05-06 05:45:54,043 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-05-06 05:45:54,043 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-05-06 05:45:54,045 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1651815950606_1324761946/in/part5:0+118\n",
            "2022-05-06 05:45:54,207 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-05-06 05:45:54,207 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-05-06 05:45:54,207 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-05-06 05:45:54,207 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-05-06 05:45:54,208 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-05-06 05:45:54,208 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-05-06 05:45:54,213 INFO mapred.LocalJobRunner: \n",
            "2022-05-06 05:45:54,213 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-05-06 05:45:54,213 INFO mapred.MapTask: Spilling map output\n",
            "2022-05-06 05:45:54,214 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-05-06 05:45:54,214 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-05-06 05:45:54,215 INFO mapred.MapTask: Finished spill 0\n",
            "2022-05-06 05:45:54,217 INFO mapred.Task: Task:attempt_local961884597_0001_m_000007_0 is done. And is in the process of committing\n",
            "2022-05-06 05:45:54,219 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-05-06 05:45:54,219 INFO mapred.Task: Task 'attempt_local961884597_0001_m_000007_0' done.\n",
            "2022-05-06 05:45:54,220 INFO mapred.Task: Final Counters for attempt_local961884597_0001_m_000007_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=296951\n",
            "\t\tFILE: Number of bytes written=920106\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=996147200\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-05-06 05:45:54,220 INFO mapred.LocalJobRunner: Finishing task: attempt_local961884597_0001_m_000007_0\n",
            "2022-05-06 05:45:54,220 INFO mapred.LocalJobRunner: Starting task: attempt_local961884597_0001_m_000008_0\n",
            "2022-05-06 05:45:54,224 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-05-06 05:45:54,224 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-05-06 05:45:54,224 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-05-06 05:45:54,226 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1651815950606_1324761946/in/part14:0+118\n",
            "2022-05-06 05:45:54,381 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-05-06 05:45:54,381 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-05-06 05:45:54,381 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-05-06 05:45:54,381 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-05-06 05:45:54,382 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-05-06 05:45:54,382 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-05-06 05:45:54,389 INFO mapred.LocalJobRunner: \n",
            "2022-05-06 05:45:54,389 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-05-06 05:45:54,389 INFO mapred.MapTask: Spilling map output\n",
            "2022-05-06 05:45:54,389 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-05-06 05:45:54,389 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-05-06 05:45:54,391 INFO mapred.MapTask: Finished spill 0\n",
            "2022-05-06 05:45:54,393 INFO mapred.Task: Task:attempt_local961884597_0001_m_000008_0 is done. And is in the process of committing\n",
            "2022-05-06 05:45:54,395 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-05-06 05:45:54,395 INFO mapred.Task: Task 'attempt_local961884597_0001_m_000008_0' done.\n",
            "2022-05-06 05:45:54,396 INFO mapred.Task: Final Counters for attempt_local961884597_0001_m_000008_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=298146\n",
            "\t\tFILE: Number of bytes written=920166\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=129\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1101529088\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-05-06 05:45:54,396 INFO mapred.LocalJobRunner: Finishing task: attempt_local961884597_0001_m_000008_0\n",
            "2022-05-06 05:45:54,396 INFO mapred.LocalJobRunner: Starting task: attempt_local961884597_0001_m_000009_0\n",
            "2022-05-06 05:45:54,399 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-05-06 05:45:54,399 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-05-06 05:45:54,400 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-05-06 05:45:54,401 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1651815950606_1324761946/in/part11:0+118\n",
            "2022-05-06 05:45:54,552 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-05-06 05:45:54,552 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-05-06 05:45:54,552 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-05-06 05:45:54,552 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-05-06 05:45:54,552 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-05-06 05:45:54,556 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-05-06 05:45:54,563 INFO mapred.LocalJobRunner: \n",
            "2022-05-06 05:45:54,563 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-05-06 05:45:54,563 INFO mapred.MapTask: Spilling map output\n",
            "2022-05-06 05:45:54,563 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-05-06 05:45:54,563 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-05-06 05:45:54,565 INFO mapred.MapTask: Finished spill 0\n",
            "2022-05-06 05:45:54,567 INFO mapred.Task: Task:attempt_local961884597_0001_m_000009_0 is done. And is in the process of committing\n",
            "2022-05-06 05:45:54,568 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-05-06 05:45:54,569 INFO mapred.Task: Task 'attempt_local961884597_0001_m_000009_0' done.\n",
            "2022-05-06 05:45:54,569 INFO mapred.Task: Final Counters for attempt_local961884597_0001_m_000009_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=299341\n",
            "\t\tFILE: Number of bytes written=920226\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=129\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1206910976\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-05-06 05:45:54,569 INFO mapred.LocalJobRunner: Finishing task: attempt_local961884597_0001_m_000009_0\n",
            "2022-05-06 05:45:54,571 INFO mapred.LocalJobRunner: Starting task: attempt_local961884597_0001_m_000010_0\n",
            "2022-05-06 05:45:54,573 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-05-06 05:45:54,573 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-05-06 05:45:54,574 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-05-06 05:45:54,575 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1651815950606_1324761946/in/part13:0+118\n",
            "2022-05-06 05:45:54,735 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-05-06 05:45:54,735 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-05-06 05:45:54,735 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-05-06 05:45:54,735 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-05-06 05:45:54,735 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-05-06 05:45:54,736 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-05-06 05:45:54,741 INFO mapred.LocalJobRunner: \n",
            "2022-05-06 05:45:54,741 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-05-06 05:45:54,741 INFO mapred.MapTask: Spilling map output\n",
            "2022-05-06 05:45:54,741 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-05-06 05:45:54,741 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-05-06 05:45:54,743 INFO mapred.MapTask: Finished spill 0\n",
            "2022-05-06 05:45:54,748 INFO mapred.Task: Task:attempt_local961884597_0001_m_000010_0 is done. And is in the process of committing\n",
            "2022-05-06 05:45:54,754 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-05-06 05:45:54,754 INFO mapred.Task: Task 'attempt_local961884597_0001_m_000010_0' done.\n",
            "2022-05-06 05:45:54,755 INFO mapred.Task: Final Counters for attempt_local961884597_0001_m_000010_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=300536\n",
            "\t\tFILE: Number of bytes written=920286\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=129\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1312292864\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-05-06 05:45:54,755 INFO mapred.LocalJobRunner: Finishing task: attempt_local961884597_0001_m_000010_0\n",
            "2022-05-06 05:45:54,755 INFO mapred.LocalJobRunner: Starting task: attempt_local961884597_0001_m_000011_0\n",
            "2022-05-06 05:45:54,756 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-05-06 05:45:54,756 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-05-06 05:45:54,757 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-05-06 05:45:54,758 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1651815950606_1324761946/in/part8:0+118\n",
            "2022-05-06 05:45:54,911 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-05-06 05:45:54,911 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-05-06 05:45:54,911 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-05-06 05:45:54,911 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-05-06 05:45:54,911 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-05-06 05:45:54,912 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-05-06 05:45:54,916 INFO mapred.LocalJobRunner: \n",
            "2022-05-06 05:45:54,917 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-05-06 05:45:54,917 INFO mapred.MapTask: Spilling map output\n",
            "2022-05-06 05:45:54,917 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-05-06 05:45:54,917 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-05-06 05:45:54,918 INFO mapred.MapTask: Finished spill 0\n",
            "2022-05-06 05:45:54,925 INFO mapred.Task: Task:attempt_local961884597_0001_m_000011_0 is done. And is in the process of committing\n",
            "2022-05-06 05:45:54,928 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-05-06 05:45:54,928 INFO mapred.Task: Task 'attempt_local961884597_0001_m_000011_0' done.\n",
            "2022-05-06 05:45:54,933 INFO mapred.Task: Final Counters for attempt_local961884597_0001_m_000011_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=301731\n",
            "\t\tFILE: Number of bytes written=920346\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1417674752\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-05-06 05:45:54,933 INFO mapred.LocalJobRunner: Finishing task: attempt_local961884597_0001_m_000011_0\n",
            "2022-05-06 05:45:54,933 INFO mapred.LocalJobRunner: Starting task: attempt_local961884597_0001_m_000012_0\n",
            "2022-05-06 05:45:54,935 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-05-06 05:45:54,935 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-05-06 05:45:54,936 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-05-06 05:45:54,937 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1651815950606_1324761946/in/part4:0+118\n",
            "2022-05-06 05:45:55,076 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-05-06 05:45:55,076 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-05-06 05:45:55,076 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-05-06 05:45:55,076 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-05-06 05:45:55,076 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-05-06 05:45:55,077 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-05-06 05:45:55,083 INFO mapred.LocalJobRunner: \n",
            "2022-05-06 05:45:55,084 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-05-06 05:45:55,084 INFO mapred.MapTask: Spilling map output\n",
            "2022-05-06 05:45:55,084 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-05-06 05:45:55,084 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-05-06 05:45:55,085 INFO mapred.MapTask: Finished spill 0\n",
            "2022-05-06 05:45:55,089 INFO mapred.Task: Task:attempt_local961884597_0001_m_000012_0 is done. And is in the process of committing\n",
            "2022-05-06 05:45:55,091 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-05-06 05:45:55,092 INFO mapred.Task: Task 'attempt_local961884597_0001_m_000012_0' done.\n",
            "2022-05-06 05:45:55,092 INFO mapred.Task: Final Counters for attempt_local961884597_0001_m_000012_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=302414\n",
            "\t\tFILE: Number of bytes written=920406\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1523056640\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-05-06 05:45:55,092 INFO mapred.LocalJobRunner: Finishing task: attempt_local961884597_0001_m_000012_0\n",
            "2022-05-06 05:45:55,092 INFO mapred.LocalJobRunner: Starting task: attempt_local961884597_0001_m_000013_0\n",
            "2022-05-06 05:45:55,094 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-05-06 05:45:55,094 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-05-06 05:45:55,095 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-05-06 05:45:55,096 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1651815950606_1324761946/in/part15:0+118\n",
            "2022-05-06 05:45:55,162 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-05-06 05:45:55,162 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-05-06 05:45:55,162 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-05-06 05:45:55,162 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-05-06 05:45:55,162 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-05-06 05:45:55,191 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-05-06 05:45:55,195 INFO mapred.LocalJobRunner: \n",
            "2022-05-06 05:45:55,196 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-05-06 05:45:55,196 INFO mapred.MapTask: Spilling map output\n",
            "2022-05-06 05:45:55,196 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-05-06 05:45:55,196 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-05-06 05:45:55,197 INFO mapred.MapTask: Finished spill 0\n",
            "2022-05-06 05:45:55,200 INFO mapred.Task: Task:attempt_local961884597_0001_m_000013_0 is done. And is in the process of committing\n",
            "2022-05-06 05:45:55,204 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-05-06 05:45:55,204 INFO mapred.Task: Task 'attempt_local961884597_0001_m_000013_0' done.\n",
            "2022-05-06 05:45:55,204 INFO mapred.Task: Final Counters for attempt_local961884597_0001_m_000013_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=303097\n",
            "\t\tFILE: Number of bytes written=920466\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=129\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=28\n",
            "\t\tTotal committed heap usage (bytes)=1628438528\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-05-06 05:45:55,204 INFO mapred.LocalJobRunner: Finishing task: attempt_local961884597_0001_m_000013_0\n",
            "2022-05-06 05:45:55,204 INFO mapred.LocalJobRunner: Starting task: attempt_local961884597_0001_m_000014_0\n",
            "2022-05-06 05:45:55,206 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-05-06 05:45:55,206 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-05-06 05:45:55,206 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-05-06 05:45:55,207 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1651815950606_1324761946/in/part12:0+118\n",
            "2022-05-06 05:45:55,275 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-05-06 05:45:55,276 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-05-06 05:45:55,276 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-05-06 05:45:55,276 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-05-06 05:45:55,276 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-05-06 05:45:55,278 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-05-06 05:45:55,284 INFO mapred.LocalJobRunner: \n",
            "2022-05-06 05:45:55,284 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-05-06 05:45:55,284 INFO mapred.MapTask: Spilling map output\n",
            "2022-05-06 05:45:55,284 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-05-06 05:45:55,284 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-05-06 05:45:55,285 INFO mapred.MapTask: Finished spill 0\n",
            "2022-05-06 05:45:55,287 INFO mapred.Task: Task:attempt_local961884597_0001_m_000014_0 is done. And is in the process of committing\n",
            "2022-05-06 05:45:55,289 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-05-06 05:45:55,289 INFO mapred.Task: Task 'attempt_local961884597_0001_m_000014_0' done.\n",
            "2022-05-06 05:45:55,290 INFO mapred.Task: Final Counters for attempt_local961884597_0001_m_000014_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=303780\n",
            "\t\tFILE: Number of bytes written=920526\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=129\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1733820416\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-05-06 05:45:55,290 INFO mapred.LocalJobRunner: Finishing task: attempt_local961884597_0001_m_000014_0\n",
            "2022-05-06 05:45:55,290 INFO mapred.LocalJobRunner: Starting task: attempt_local961884597_0001_m_000015_0\n",
            "2022-05-06 05:45:55,291 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-05-06 05:45:55,291 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-05-06 05:45:55,292 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-05-06 05:45:55,294 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1651815950606_1324761946/in/part6:0+118\n",
            "2022-05-06 05:45:55,367 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-05-06 05:45:55,368 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-05-06 05:45:55,368 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-05-06 05:45:55,368 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-05-06 05:45:55,368 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-05-06 05:45:55,368 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-05-06 05:45:55,374 INFO mapred.LocalJobRunner: \n",
            "2022-05-06 05:45:55,374 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-05-06 05:45:55,374 INFO mapred.MapTask: Spilling map output\n",
            "2022-05-06 05:45:55,374 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-05-06 05:45:55,374 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-05-06 05:45:55,376 INFO mapred.MapTask: Finished spill 0\n",
            "2022-05-06 05:45:55,378 INFO mapred.Task: Task:attempt_local961884597_0001_m_000015_0 is done. And is in the process of committing\n",
            "2022-05-06 05:45:55,379 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-05-06 05:45:55,379 INFO mapred.Task: Task 'attempt_local961884597_0001_m_000015_0' done.\n",
            "2022-05-06 05:45:55,379 INFO mapred.Task: Final Counters for attempt_local961884597_0001_m_000015_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=304463\n",
            "\t\tFILE: Number of bytes written=920586\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1839202304\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-05-06 05:45:55,379 INFO mapred.LocalJobRunner: Finishing task: attempt_local961884597_0001_m_000015_0\n",
            "2022-05-06 05:45:55,380 INFO mapred.LocalJobRunner: map task executor complete.\n",
            "2022-05-06 05:45:55,386 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
            "2022-05-06 05:45:55,387 INFO mapred.LocalJobRunner: Starting task: attempt_local961884597_0001_r_000000_0\n",
            "2022-05-06 05:45:55,406 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-05-06 05:45:55,406 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-05-06 05:45:55,406 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-05-06 05:45:55,410 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7096b972\n",
            "2022-05-06 05:45:55,411 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2022-05-06 05:45:55,435 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2119434240, maxSingleShuffleLimit=529858560, mergeThreshold=1398826624, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2022-05-06 05:45:55,437 INFO reduce.EventFetcher: attempt_local961884597_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2022-05-06 05:45:55,491 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local961884597_0001_m_000003_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-05-06 05:45:55,500 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local961884597_0001_m_000003_0\n",
            "2022-05-06 05:45:55,500 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->24\n",
            "2022-05-06 05:45:55,504 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local961884597_0001_m_000009_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-05-06 05:45:55,509 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local961884597_0001_m_000009_0\n",
            "2022-05-06 05:45:55,509 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 2, commitMemory -> 24, usedMemory ->48\n",
            "2022-05-06 05:45:55,516 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local961884597_0001_m_000002_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-05-06 05:45:55,526 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local961884597_0001_m_000002_0\n",
            "2022-05-06 05:45:55,526 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 3, commitMemory -> 48, usedMemory ->72\n",
            "2022-05-06 05:45:55,528 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local961884597_0001_m_000015_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-05-06 05:45:55,533 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local961884597_0001_m_000015_0\n",
            "2022-05-06 05:45:55,533 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 4, commitMemory -> 72, usedMemory ->96\n",
            "2022-05-06 05:45:55,534 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local961884597_0001_m_000008_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-05-06 05:45:55,535 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local961884597_0001_m_000008_0\n",
            "2022-05-06 05:45:55,535 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 5, commitMemory -> 96, usedMemory ->120\n",
            "2022-05-06 05:45:55,536 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local961884597_0001_m_000014_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-05-06 05:45:55,536 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local961884597_0001_m_000014_0\n",
            "2022-05-06 05:45:55,537 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 6, commitMemory -> 120, usedMemory ->144\n",
            "2022-05-06 05:45:55,538 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local961884597_0001_m_000001_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-05-06 05:45:55,538 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local961884597_0001_m_000001_0\n",
            "2022-05-06 05:45:55,538 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 7, commitMemory -> 144, usedMemory ->168\n",
            "2022-05-06 05:45:55,539 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local961884597_0001_m_000007_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-05-06 05:45:55,547 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local961884597_0001_m_000007_0\n",
            "2022-05-06 05:45:55,547 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 8, commitMemory -> 168, usedMemory ->192\n",
            "2022-05-06 05:45:55,550 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local961884597_0001_m_000000_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-05-06 05:45:55,551 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local961884597_0001_m_000000_0\n",
            "2022-05-06 05:45:55,551 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 9, commitMemory -> 192, usedMemory ->216\n",
            "2022-05-06 05:45:55,552 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local961884597_0001_m_000013_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-05-06 05:45:55,552 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local961884597_0001_m_000013_0\n",
            "2022-05-06 05:45:55,553 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 10, commitMemory -> 216, usedMemory ->240\n",
            "2022-05-06 05:45:55,554 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local961884597_0001_m_000006_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-05-06 05:45:55,554 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local961884597_0001_m_000006_0\n",
            "2022-05-06 05:45:55,554 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 11, commitMemory -> 240, usedMemory ->264\n",
            "2022-05-06 05:45:55,555 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local961884597_0001_m_000012_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-05-06 05:45:55,556 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local961884597_0001_m_000012_0\n",
            "2022-05-06 05:45:55,556 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 12, commitMemory -> 264, usedMemory ->288\n",
            "2022-05-06 05:45:55,557 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local961884597_0001_m_000005_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-05-06 05:45:55,557 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local961884597_0001_m_000005_0\n",
            "2022-05-06 05:45:55,558 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 13, commitMemory -> 288, usedMemory ->312\n",
            "2022-05-06 05:45:55,559 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local961884597_0001_m_000011_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-05-06 05:45:55,559 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local961884597_0001_m_000011_0\n",
            "2022-05-06 05:45:55,559 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 14, commitMemory -> 312, usedMemory ->336\n",
            "2022-05-06 05:45:55,560 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local961884597_0001_m_000004_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-05-06 05:45:55,561 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local961884597_0001_m_000004_0\n",
            "2022-05-06 05:45:55,561 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 15, commitMemory -> 336, usedMemory ->360\n",
            "2022-05-06 05:45:55,563 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local961884597_0001_m_000010_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-05-06 05:45:55,563 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local961884597_0001_m_000010_0\n",
            "2022-05-06 05:45:55,563 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 16, commitMemory -> 360, usedMemory ->384\n",
            "2022-05-06 05:45:55,563 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
            "2022-05-06 05:45:55,564 INFO mapred.LocalJobRunner: 16 / 16 copied.\n",
            "2022-05-06 05:45:55,565 INFO reduce.MergeManagerImpl: finalMerge called with 16 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2022-05-06 05:45:55,571 INFO mapred.Merger: Merging 16 sorted segments\n",
            "2022-05-06 05:45:55,572 INFO mapred.Merger: Down to the last merge-pass, with 16 segments left of total size: 336 bytes\n",
            "2022-05-06 05:45:55,574 INFO reduce.MergeManagerImpl: Merged 16 segments, 384 bytes to disk to satisfy reduce memory limit\n",
            "2022-05-06 05:45:55,577 INFO reduce.MergeManagerImpl: Merging 1 files, 358 bytes from disk\n",
            "2022-05-06 05:45:55,578 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
            "2022-05-06 05:45:55,578 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2022-05-06 05:45:55,578 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 351 bytes\n",
            "2022-05-06 05:45:55,580 INFO mapred.LocalJobRunner: 16 / 16 copied.\n",
            "2022-05-06 05:45:55,583 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "2022-05-06 05:45:55,592 INFO mapred.Task: Task:attempt_local961884597_0001_r_000000_0 is done. And is in the process of committing\n",
            "2022-05-06 05:45:55,593 INFO mapred.LocalJobRunner: 16 / 16 copied.\n",
            "2022-05-06 05:45:55,593 INFO mapred.Task: Task attempt_local961884597_0001_r_000000_0 is allowed to commit now\n",
            "2022-05-06 05:45:55,595 INFO output.FileOutputCommitter: Saved output of task 'attempt_local961884597_0001_r_000000_0' to file:/content/QuasiMonteCarlo_1651815950606_1324761946/out\n",
            "2022-05-06 05:45:55,596 INFO mapred.LocalJobRunner: reduce > reduce\n",
            "2022-05-06 05:45:55,596 INFO mapred.Task: Task 'attempt_local961884597_0001_r_000000_0' done.\n",
            "2022-05-06 05:45:55,596 INFO mapred.Task: Final Counters for attempt_local961884597_0001_r_000000_0: Counters: 24\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=305781\n",
            "\t\tFILE: Number of bytes written=921183\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=2\n",
            "\t\tReduce shuffle bytes=448\n",
            "\t\tReduce input records=32\n",
            "\t\tReduce output records=0\n",
            "\t\tSpilled Records=32\n",
            "\t\tShuffled Maps =16\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=16\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1839202304\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=109\n",
            "2022-05-06 05:45:55,596 INFO mapred.LocalJobRunner: Finishing task: attempt_local961884597_0001_r_000000_0\n",
            "2022-05-06 05:45:55,596 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
            "2022-05-06 05:45:56,366 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2022-05-06 05:45:56,366 INFO mapreduce.Job: Job job_local961884597_0001 completed successfully\n",
            "2022-05-06 05:45:56,395 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=5044029\n",
            "\t\tFILE: Number of bytes written=15643359\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=16\n",
            "\t\tMap output records=32\n",
            "\t\tMap output bytes=288\n",
            "\t\tMap output materialized bytes=448\n",
            "\t\tInput split bytes=2054\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=2\n",
            "\t\tReduce shuffle bytes=448\n",
            "\t\tReduce input records=32\n",
            "\t\tReduce output records=0\n",
            "\t\tSpilled Records=64\n",
            "\t\tShuffled Maps =16\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=16\n",
            "\t\tGC time elapsed (ms)=28\n",
            "\t\tTotal committed heap usage (bytes)=18620612608\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=2080\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=109\n",
            "Job Finished in 4.976 seconds\n",
            "Estimated value of Pi is 3.14157500000000000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC9WSzgMprwr"
      },
      "source": [
        "# 4 Run WordCount with Hadoop\n",
        "Instead of using Java for Map and Reduce methods, we use the streaming API of Hadoop and two simple python programs as mapper.py and reducer.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxloM8fzqORx"
      },
      "source": [
        "# get mapper.py reducer.py from G_drive\n",
        "#!gdown https://drive.google.com/uc?id=1VTzQ18cWAj6L29ncW6sABy-ITmDCcv5r\n",
        "#!gdown https://drive.google.com/uc?id=1Or8Cbf9AsFMHStjMzDw3pXCd6TZ0dqxJ\n",
        "\n",
        "#get mapper.py reducer.py from this git repository\n",
        "!wget -q https://raw.githubusercontent.com/Praxis-QR/BDSN/main/mapper.py\n",
        "!wget -q https://raw.githubusercontent.com/Praxis-QR/BDSN/main/reducer.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRWPIMj9qpZK"
      },
      "source": [
        "# to see the codes, uncomment the following lines\n",
        "#!cat mapper.py\n",
        "#print(\"\\n----------------------    see above for mapper, see below for reducer\")\n",
        "#!cat reducer.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MQ_4eaxqlCW"
      },
      "source": [
        "# python codes are made executable\n",
        "!chmod u+rwx /content/mapper.py\n",
        "!chmod u+rwx /content/reducer.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yfxo4CJrCtJ"
      },
      "source": [
        "# get a simple txt file as data for word count\n",
        "# or you can upload your own\n",
        "#!gdown https://drive.google.com/uc?id=1R5W0UVH2S3JjPxerqyX4ue5y6tMt0Wkk\n",
        "!wget -q https://raw.githubusercontent.com/Praxis-QR/BDSN/main/Chronotantra.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W38-6u0KrSrp",
        "outputId": "dca93c9b-56d8-4d09-be4d-242384e56bad"
      },
      "source": [
        "# locate the streaming jar file\n",
        "!find / -name 'hadoop-streaming*.jar'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "find: ‘/proc/28/task/28/net’: Invalid argument\n",
            "find: ‘/proc/28/net’: Invalid argument\n",
            "/usr/local/hadoop-3.3.2/share/hadoop/tools/lib/hadoop-streaming-3.3.2.jar\n",
            "/usr/local/hadoop-3.3.2/share/hadoop/tools/sources/hadoop-streaming-3.3.2-test-sources.jar\n",
            "/usr/local/hadoop-3.3.2/share/hadoop/tools/sources/hadoop-streaming-3.3.2-sources.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h60r05EPk-xF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ee296b8-e660-4451-b5ff-35da6e86632b"
      },
      "source": [
        "# remove output directories\n",
        "!rm -r wc_out\n",
        "!rm -r wc2_out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'wc_out': No such file or directory\n",
            "rm: cannot remove 'wc2_out': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH-I6ow7rl9k",
        "outputId": "f2f78977-1231-410f-cd71-fa8f10e6309e"
      },
      "source": [
        "# execute the streaming jar with proper parameters\n",
        "# four parameters are input file, output directory, the mapper progra, the reducer program\n",
        "#\n",
        "#!hadoop jar /usr/local/hadoop-3.3.0/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar -input /content/hobbit.txt -output /content/wc_out -file /content/mapper.py  -file /content/reducer.py  -mapper 'python mapper.py'  -reducer 'python reducer.py'\n",
        "#!hadoop jar /usr/local/hadoop-3.3.0/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar -input /content/Chronotantra.txt -output /content/wc_out -file /content/mapper.py  -file /content/reducer.py  -mapper 'python mapper.py'  -reducer 'python reducer.py'\n",
        "#!hadoop jar /usr/local/hadoop-3.3.0/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar -input /content/Chronotantra.txt -output /content/wc_out  -mapper 'python mapper.py'  -reducer 'python reducer.py'\n",
        "!hadoop jar /usr/local/hadoop-3.3.2/share/hadoop/tools/lib/hadoop-streaming-3.3.2.jar -input /content/Chronotantra.txt -output /content/wc_out  -mapper 'python mapper.py'  -reducer 'python reducer.py'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-06 05:52:01,533 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
            "2022-05-06 05:52:01,651 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
            "2022-05-06 05:52:01,651 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
            "2022-05-06 05:52:01,671 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2022-05-06 05:52:01,883 INFO mapred.FileInputFormat: Total input files to process : 1\n",
            "2022-05-06 05:52:01,907 INFO mapreduce.JobSubmitter: number of splits:1\n",
            "2022-05-06 05:52:02,145 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local575339868_0001\n",
            "2022-05-06 05:52:02,145 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2022-05-06 05:52:02,368 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2022-05-06 05:52:02,370 INFO mapreduce.Job: Running job: job_local575339868_0001\n",
            "2022-05-06 05:52:02,377 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2022-05-06 05:52:02,379 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
            "2022-05-06 05:52:02,385 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-05-06 05:52:02,385 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-05-06 05:52:02,452 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
            "2022-05-06 05:52:02,459 INFO mapred.LocalJobRunner: Starting task: attempt_local575339868_0001_m_000000_0\n",
            "2022-05-06 05:52:02,489 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-05-06 05:52:02,489 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-05-06 05:52:02,516 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-05-06 05:52:02,526 INFO mapred.MapTask: Processing split: file:/content/Chronotantra.txt:0+353890\n",
            "2022-05-06 05:52:02,550 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2022-05-06 05:52:02,633 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-05-06 05:52:02,633 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-05-06 05:52:02,633 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-05-06 05:52:02,633 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-05-06 05:52:02,633 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-05-06 05:52:02,637 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-05-06 05:52:02,646 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2022-05-06 05:52:02,652 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
            "2022-05-06 05:52:02,654 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
            "2022-05-06 05:52:02,655 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
            "2022-05-06 05:52:02,655 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
            "2022-05-06 05:52:02,656 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
            "2022-05-06 05:52:02,656 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
            "2022-05-06 05:52:02,658 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
            "2022-05-06 05:52:02,659 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
            "2022-05-06 05:52:02,659 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
            "2022-05-06 05:52:02,659 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
            "2022-05-06 05:52:02,660 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "2022-05-06 05:52:02,660 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
            "2022-05-06 05:52:02,701 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-05-06 05:52:02,704 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-05-06 05:52:02,706 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-05-06 05:52:03,376 INFO mapreduce.Job: Job job_local575339868_0001 running in uber mode : false\n",
            "2022-05-06 05:52:03,377 INFO mapreduce.Job:  map 0% reduce 0%\n",
            "2022-05-06 05:52:04,473 INFO streaming.PipeMapRed: Records R/W=971/1\n",
            "2022-05-06 05:52:04,531 INFO streaming.PipeMapRed: R/W/S=1000/4408/0 in:1000=1000/1 [rec/s] out:4408=4408/1 [rec/s]\n",
            "2022-05-06 05:52:04,871 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2022-05-06 05:52:04,872 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2022-05-06 05:52:04,876 INFO mapred.LocalJobRunner: \n",
            "2022-05-06 05:52:04,876 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-05-06 05:52:04,876 INFO mapred.MapTask: Spilling map output\n",
            "2022-05-06 05:52:04,876 INFO mapred.MapTask: bufstart = 0; bufend = 261471; bufvoid = 104857600\n",
            "2022-05-06 05:52:04,876 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26100800(104403200); length = 113597/6553600\n",
            "2022-05-06 05:52:05,026 INFO mapred.MapTask: Finished spill 0\n",
            "2022-05-06 05:52:05,043 INFO mapred.Task: Task:attempt_local575339868_0001_m_000000_0 is done. And is in the process of committing\n",
            "2022-05-06 05:52:05,046 INFO mapred.LocalJobRunner: Records R/W=971/1\n",
            "2022-05-06 05:52:05,046 INFO mapred.Task: Task 'attempt_local575339868_0001_m_000000_0' done.\n",
            "2022-05-06 05:52:05,057 INFO mapred.Task: Final Counters for attempt_local575339868_0001_m_000000_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=495269\n",
            "\t\tFILE: Number of bytes written=1096832\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=2647\n",
            "\t\tMap output records=28400\n",
            "\t\tMap output bytes=261471\n",
            "\t\tMap output materialized bytes=318277\n",
            "\t\tInput split bytes=82\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=28400\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=258473984\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=353890\n",
            "2022-05-06 05:52:05,057 INFO mapred.LocalJobRunner: Finishing task: attempt_local575339868_0001_m_000000_0\n",
            "2022-05-06 05:52:05,058 INFO mapred.LocalJobRunner: map task executor complete.\n",
            "2022-05-06 05:52:05,061 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
            "2022-05-06 05:52:05,062 INFO mapred.LocalJobRunner: Starting task: attempt_local575339868_0001_r_000000_0\n",
            "2022-05-06 05:52:05,074 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-05-06 05:52:05,074 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-05-06 05:52:05,075 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-05-06 05:52:05,086 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@703637ff\n",
            "2022-05-06 05:52:05,089 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2022-05-06 05:52:05,113 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2119434240, maxSingleShuffleLimit=529858560, mergeThreshold=1398826624, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2022-05-06 05:52:05,116 INFO reduce.EventFetcher: attempt_local575339868_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2022-05-06 05:52:05,166 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local575339868_0001_m_000000_0 decomp: 318273 len: 318277 to MEMORY\n",
            "2022-05-06 05:52:05,171 INFO reduce.InMemoryMapOutput: Read 318273 bytes from map-output for attempt_local575339868_0001_m_000000_0\n",
            "2022-05-06 05:52:05,173 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 318273, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->318273\n",
            "2022-05-06 05:52:05,177 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
            "2022-05-06 05:52:05,178 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2022-05-06 05:52:05,178 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2022-05-06 05:52:05,188 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2022-05-06 05:52:05,189 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 318269 bytes\n",
            "2022-05-06 05:52:05,235 INFO reduce.MergeManagerImpl: Merged 1 segments, 318273 bytes to disk to satisfy reduce memory limit\n",
            "2022-05-06 05:52:05,235 INFO reduce.MergeManagerImpl: Merging 1 files, 318277 bytes from disk\n",
            "2022-05-06 05:52:05,237 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
            "2022-05-06 05:52:05,237 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2022-05-06 05:52:05,238 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 318269 bytes\n",
            "2022-05-06 05:52:05,238 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2022-05-06 05:52:05,253 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, reducer.py]\n",
            "2022-05-06 05:52:05,257 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
            "2022-05-06 05:52:05,259 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
            "2022-05-06 05:52:05,280 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-05-06 05:52:05,280 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-05-06 05:52:05,282 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-05-06 05:52:05,295 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-05-06 05:52:05,348 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-05-06 05:52:05,381 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2022-05-06 05:52:05,452 INFO streaming.PipeMapRed: Records R/W=14053/1\n",
            "2022-05-06 05:52:05,559 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2022-05-06 05:52:05,559 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2022-05-06 05:52:05,561 INFO mapred.Task: Task:attempt_local575339868_0001_r_000000_0 is done. And is in the process of committing\n",
            "2022-05-06 05:52:05,565 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2022-05-06 05:52:05,565 INFO mapred.Task: Task attempt_local575339868_0001_r_000000_0 is allowed to commit now\n",
            "2022-05-06 05:52:05,567 INFO output.FileOutputCommitter: Saved output of task 'attempt_local575339868_0001_r_000000_0' to file:/content/wc_out\n",
            "2022-05-06 05:52:05,570 INFO mapred.LocalJobRunner: Records R/W=14053/1 > reduce\n",
            "2022-05-06 05:52:05,572 INFO mapred.Task: Task 'attempt_local575339868_0001_r_000000_0' done.\n",
            "2022-05-06 05:52:05,573 INFO mapred.Task: Final Counters for attempt_local575339868_0001_r_000000_0: Counters: 24\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=1131855\n",
            "\t\tFILE: Number of bytes written=1487543\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=6994\n",
            "\t\tReduce shuffle bytes=318277\n",
            "\t\tReduce input records=28400\n",
            "\t\tReduce output records=6994\n",
            "\t\tSpilled Records=28400\n",
            "\t\tShuffled Maps =1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=1\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=258473984\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=72434\n",
            "2022-05-06 05:52:05,573 INFO mapred.LocalJobRunner: Finishing task: attempt_local575339868_0001_r_000000_0\n",
            "2022-05-06 05:52:05,574 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
            "2022-05-06 05:52:06,382 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2022-05-06 05:52:06,382 INFO mapreduce.Job: Job job_local575339868_0001 completed successfully\n",
            "2022-05-06 05:52:06,397 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=1627124\n",
            "\t\tFILE: Number of bytes written=2584375\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=2647\n",
            "\t\tMap output records=28400\n",
            "\t\tMap output bytes=261471\n",
            "\t\tMap output materialized bytes=318277\n",
            "\t\tInput split bytes=82\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=6994\n",
            "\t\tReduce shuffle bytes=318277\n",
            "\t\tReduce input records=28400\n",
            "\t\tReduce output records=6994\n",
            "\t\tSpilled Records=56800\n",
            "\t\tShuffled Maps =1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=1\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=516947968\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=353890\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=72434\n",
            "2022-05-06 05:52:06,400 INFO streaming.StreamJob: Output directory: /content/wc_out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d2DTo_GsBot",
        "outputId": "e465836d-a7de-4ad0-ab8d-f085d740e630"
      },
      "source": [
        "# check output directory\n",
        "!ls wc_out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-00000  _SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91LjuJnlsKGz",
        "outputId": "fa8a22e8-e20c-45f2-d298-b18b69546910"
      },
      "source": [
        "# see actual output\n",
        "#!tail wc_out/part-00000\n",
        "!head wc_out/part-00000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\t8\n",
            "10\t2\n",
            "100\t2\n",
            "1000\t1\n",
            "105\t1\n",
            "108\t2\n",
            "109\t1\n",
            "11\t1\n",
            "110\t2\n",
            "113\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbaMQ1lWpB7O"
      },
      "source": [
        "### Sorting the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld-kLgmOpLw8"
      },
      "source": [
        "#https://www.geeksforgeeks.org/sort-command-linuxunix-examples/\n",
        "!sort -nr -k 2 -t$'\\t' wc_out/part-00000 > sorted.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K09MH8h4qNfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1b5e284-852c-4b44-ba9e-04584977da31"
      },
      "source": [
        "!head -30 sorted.txt\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "would\t346\n",
            "could\t247\n",
            "one\t198\n",
            "time\t156\n",
            "like\t145\n",
            "know\t144\n",
            "us\t134\n",
            "mars\t119\n",
            "back\t106\n",
            "even\t105\n",
            "world\t97\n",
            "something\t95\n",
            "see\t95\n",
            "well\t93\n",
            "hermit\t93\n",
            "two\t87\n",
            "people\t86\n",
            "course\t84\n",
            "around\t84\n",
            "way\t82\n",
            "first\t80\n",
            "really\t79\n",
            "new\t76\n",
            "little\t74\n",
            "long\t73\n",
            "still\t71\n",
            "information\t70\n",
            "ai\t67\n",
            "good\t63\n",
            "earth\t60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZN0vwE2pxHs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec36cdc8-6570-4e4d-e18a-80d0c42087df"
      },
      "source": [
        "!tail -30 sorted.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2150\t1\n",
            "214\t1\n",
            "206\t1\n",
            "205\t1\n",
            "2019\t1\n",
            "2018\t1\n",
            "2007\t1\n",
            "20062007\t1\n",
            "2000\t1\n",
            "1999\t1\n",
            "1970s\t1\n",
            "1956\t1\n",
            "187\t1\n",
            "186\t1\n",
            "17866\t1\n",
            "156\t1\n",
            "155\t1\n",
            "15\t1\n",
            "150\t1\n",
            "1493\t1\n",
            "133\t1\n",
            "132\t1\n",
            "12th\t1\n",
            "12700\t1\n",
            "115\t1\n",
            "113\t1\n",
            "11\t1\n",
            "109\t1\n",
            "105\t1\n",
            "1000\t1\n"
          ]
        }
      ]
    }
  ]
}