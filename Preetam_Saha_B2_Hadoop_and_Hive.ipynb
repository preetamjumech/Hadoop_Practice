{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preetamjumech/Hadoop_Practice/blob/main/Preetam_Saha_B2_Hadoop_and_Hive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwjvirExIQAM"
      },
      "source": [
        "#Hive with Hadoop\n",
        "This notebook has all the codes / commands required to install Hadoop and Hive <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK5y3g-ySDmZ"
      },
      "source": [
        "##Acknowledgements\n",
        "Hadoop Installation from [Anjaly Sam's Github Repository](https://github.com/anjalysam/Hadoop) <br>\n",
        "Hive Installation from [PhoenixNAP](https://phoenixnap.com/kb/install-hive-on-ubuntu) website"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myPIGP-mwKBD"
      },
      "source": [
        "#1 Hadoop\n",
        "Hadoop is a pre-requisite for Hive <br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9bT9M1yvyXG"
      },
      "source": [
        "## 1.1 Download, Install Hadoop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXFZuorwF25e"
      },
      "source": [
        "# The default JVM available at /usr/lib/jvm/java-11-openjdk-amd64/  works for Hadoop\n",
        "# But gives errors with Hive https://stackoverflow.com/questions/54037773/hive-exception-class-jdk-internal-loader-classloadersappclassloader-cannot\n",
        "# Hence this JVM needs to be installed\n",
        "!apt-get update > /dev/null\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bijZAdD_cBMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5a8af45-281c-426e-cdfd-287b11c3604b"
      },
      "source": [
        "# Download the latest version of Hadoop\n",
        "# Change the version number in this and subsequent cells\n",
        "#\n",
        "!wget https://downloads.apache.org/hadoop/common/hadoop-3.3.2/hadoop-3.3.2.tar.gz\n",
        "# Unzip it\n",
        "# the tar command with the -x flag to extract, -z to uncompress, -v for verbose output, and -f to specify that we’re extracting from a file\n",
        "!tar -xzf hadoop-3.3.2.tar.gz\n",
        "#copy  hadoop file to user/local\n",
        "!mv  hadoop-3.3.2/ /usr/local/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-06 07:38:59--  https://downloads.apache.org/hadoop/common/hadoop-3.3.2/hadoop-3.3.2.tar.gz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 135.181.214.104, 88.99.95.219, 2a01:4f9:3a:2c57::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|135.181.214.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 638660563 (609M) [application/x-gzip]\n",
            "Saving to: ‘hadoop-3.3.2.tar.gz’\n",
            "\n",
            "hadoop-3.3.2.tar.gz 100%[===================>] 609.07M  26.2MB/s    in 24s     \n",
            "\n",
            "2022-11-06 07:39:23 (25.3 MB/s) - ‘hadoop-3.3.2.tar.gz’ saved [638660563/638660563]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vh6Dqbbrwqpe"
      },
      "source": [
        "## 1.2 Set Environment Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OUc19ZtcBG5"
      },
      "source": [
        "#To find the default Java path\n",
        "#!readlink -f /usr/bin/java | sed \"s:bin/java::\"\n",
        "#!ls /usr/lib/jvm/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ez4T7Gs3RAn"
      },
      "source": [
        "#To set java path, go to /usr/local/hadoop-3.3.0/etc/hadoop/hadoop-env.sh then\n",
        "#. . . export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64/ . . .\n",
        "#we have used a simpler alternative route using os.environ - it works\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"   # default is changed\n",
        "#os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64/\"\n",
        "os.environ[\"HADOOP_HOME\"] = \"/usr/local/hadoop-3.3.2/\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDFgpWGLhdhl",
        "outputId": "80962f29-d8d8-4ad3-d561-6217c3542802",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Add Hadoop BIN to PATH\n",
        "# get current_path from output of previous command\n",
        "#current_path = '/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin'\n",
        "#current_path = '/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin'\n",
        "#new_path = current_path+':/usr/local/hadoop-3.3.2/bin/'\n",
        "#os.environ[\"PATH\"] = new_path\n",
        "\n",
        "current_path = os.getenv('PATH')\n",
        "#new_path = current_path+':/usr/local/hadoop-3.3.0/bin/'\n",
        "new_path = current_path+':/usr/local/hadoop-3.3.2/bin/'\n",
        "os.environ[\"PATH\"] = new_path\n",
        "!echo $PATH"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/usr/local/hadoop-3.3.2/bin/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj00rPPZyEWZ"
      },
      "source": [
        "## 1.3 Test Hadoop Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zhf-zK7NcBDF"
      },
      "source": [
        "#Running Hadoop - Test RUN, not doing anything at all\n",
        "#!/usr/local/hadoop-3.3.0/bin/hadoop\n",
        "# UNCOMMENT the following line if you want to make sure that Hadoop is alive!\n",
        "!hadoop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n3I6iqjGod-"
      },
      "source": [
        "# Testing Hadoop with PI generating sample program, should calculate value of pi = 3.14157500000000000000\n",
        "# pi example\n",
        "#Uncomment the following line if  you want to test Hadoop with pi example\n",
        "#!hadoop jar /usr/local/hadoop-3.3.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar pi 16 100000"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUlA5c3yRCx1"
      },
      "source": [
        "#2 Hive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pURJ-sKVsymi"
      },
      "source": [
        "## 2.1 Download, Install HIVE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFsywGzPRaYp",
        "outputId": "6feadcd0-9ffe-4d70-f4fe-ef6db91af8f8"
      },
      "source": [
        "# Download and Unzip the correct version and unzip\n",
        "!wget https://downloads.apache.org/hive/hive-3.1.2/apache-hive-3.1.2-bin.tar.gz\n",
        "!tar xzf apache-hive-3.1.2-bin.tar.gz"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-06 07:42:18--  https://downloads.apache.org/hive/hive-3.1.2/apache-hive-3.1.2-bin.tar.gz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 88.99.95.219, 135.181.214.104, 2a01:4f9:3a:2c57::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|88.99.95.219|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 278813748 (266M) [application/x-gzip]\n",
            "Saving to: ‘apache-hive-3.1.2-bin.tar.gz’\n",
            "\n",
            "apache-hive-3.1.2-b 100%[===================>] 265.90M  28.2MB/s    in 10s     \n",
            "\n",
            "2022-11-06 07:42:28 (26.3 MB/s) - ‘apache-hive-3.1.2-bin.tar.gz’ saved [278813748/278813748]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq6QYCVetNED"
      },
      "source": [
        "## 2.2 Set Environment *Variables*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qROUu4vSdEU",
        "outputId": "cad4d383-5761-4b3a-d175-24b12ad32a75"
      },
      "source": [
        "# Make sure that the version number is correct and is as downloaded\n",
        "os.environ[\"HIVE_HOME\"] = \"/content/apache-hive-3.1.2-bin\"\n",
        "!echo $HIVE_HOME"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/apache-hive-3.1.2-bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx3pKQ9PTBfR",
        "outputId": "429e9f20-384d-44c0-cb1b-1e3b3d573023"
      },
      "source": [
        "# current_path is set from output of previous command\n",
        "#current_path = '/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin:/usr/local/hadoop-3.3.0/bin/'\n",
        "#current_path = '/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/usr/local/hadoop-3.3.2/bin/'\n",
        "#new_path = current_path+':/content/apache-hive-3.1.2-bin/bin'\n",
        "#os.environ[\"PATH\"] = new_path\n",
        "!echo $PATH\n",
        "\n",
        "\n",
        "current_path = os.getenv('PATH')\n",
        "#new_path = current_path+':/usr/local/hadoop-3.3.0/bin/'\n",
        "new_path = current_path+':/content/apache-hive-3.1.2-bin/bin'\n",
        "os.environ[\"PATH\"] = new_path\n",
        "!echo $PATH"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/usr/local/hadoop-3.3.2/bin/\n",
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/usr/local/hadoop-3.3.2/bin/:/content/apache-hive-3.1.2-bin/bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfiA2LItT_L2",
        "outputId": "599a8d39-03b6-4d39-a381-4f3d45e62b11"
      },
      "source": [
        "!echo $JAVA_HOME\n",
        "!echo $HADOOP_HOME\n",
        "!echo $HIVE_HOME"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/jvm/java-8-openjdk-amd64\n",
            "/usr/local/hadoop-3.3.2/\n",
            "/content/apache-hive-3.1.2-bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AryjHG4ltfEe"
      },
      "source": [
        "## 2.3 Set up HDFS Directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dry58UPMVTat",
        "outputId": "f84541ab-8925-42b6-fd24-865b7364d62c"
      },
      "source": [
        "!hdfs dfs -mkdir /tmp\n",
        "!hdfs dfs -chmod g+w /tmp\n",
        "#!hdfs dfs -ls /\n",
        "!hdfs dfs -mkdir -p /content/warehouse\n",
        "!hdfs dfs -chmod g+w /content/warehouse\n",
        "#!hdfs dfs -ls /content/"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: `/tmp': File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### these are hdfs directiories. so commands are hdfs, if we search such directiories in cluster machines, we wil not find such directories. we domt know where it is. "
      ],
      "metadata": {
        "id": "a--VpBIZ6SS-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VrvjhfG2JXs"
      },
      "source": [
        "## 2.4 Initialise HIVE - note and fix errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLX7AvL8YLMY"
      },
      "source": [
        "# TYPE this command, do not copy and paste. Non printing characters cause havoc \n",
        "# There will be two errors, that we will fix\n",
        "# UNCOMMENT the following line if you WISH TO SEE the errors\n",
        "!schematool -initSchema -dbType derby\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# It gives us warnings, becuase there are multiple logging sub-systems.hadoop has logging sub-system, hive has logging sub-system. "
      ],
      "metadata": {
        "id": "u2TUGPJb7OYb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v21CxgGLuJPQ"
      },
      "source": [
        "### 2.4.1 Fix One Warning, One Error \n",
        "SLF4J(simple logging fecade for JAVA) is duplicate, need to locate them and remove one <br>\n",
        "Guava jar version is low"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Becy3BABuE8b",
        "outputId": "6e77e3e4-1315-45e5-ec7b-bf3b46d546c6"
      },
      "source": [
        "# locate multiple instances of slf4j ...\n",
        "!ls $HADOOP_HOME/share/hadoop/common/lib/*slf4j*\n",
        "!ls $HIVE_HOME/lib/*slf4j*"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/hadoop-3.3.2//share/hadoop/common/lib/jul-to-slf4j-1.7.30.jar\n",
            "/usr/local/hadoop-3.3.2//share/hadoop/common/lib/slf4j-api-1.7.30.jar\n",
            "/usr/local/hadoop-3.3.2//share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar\n",
            "/content/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEUomnHGu4kR"
      },
      "source": [
        "# removed the logging jar from Hive, retaining the Hadoop jar\n",
        "!mv /content/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar ./"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwLAYh7TY4ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b71d4fdc-67c0-484c-f15f-2380d04d3235"
      },
      "source": [
        "# guava jar needs to above v 20\n",
        "# https://stackoverflow.com/questions/45247193/nosuchmethoderror-com-google-common-base-preconditions-checkargumentzljava-lan\n",
        "!ls $HIVE_HOME/lib/gu*"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/apache-hive-3.1.2-bin/lib/guava-19.0.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### so, we have to remove the 19 version. bring the 27 version which is available with hadoop.It reduces coding errors, facilitates standard coding practices and boost productivity by making code concise and easy to read"
      ],
      "metadata": {
        "id": "1TS-E_Wu9Orf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHpmyrbkZFad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fbc8011-2ea0-46dd-8234-da07a2d5cad1"
      },
      "source": [
        "# the one available with Hadoop is better, v 27\n",
        "!ls $HADOOP_HOME/share/hadoop/hdfs/lib/gu*"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/hadoop-3.3.2//share/hadoop/hdfs/lib/guava-27.0-jre.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ3Ex1vyZeZG"
      },
      "source": [
        "# Remove the Hive Guava and replace with Hadoop Guava\n",
        "!mv $HIVE_HOME/lib/guava-19.0.jar ./\n",
        "!cp $HADOOP_HOME/share/hadoop/hdfs/lib/guava-27.0-jre.jar $HIVE_HOME/lib/"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdtNOXy8v4iD"
      },
      "source": [
        "##2.5 Initialize HIVE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Tzw4XkApRg3",
        "outputId": "5adfbba3-08ef-49f3-93a6-87d235ed7a31"
      },
      "source": [
        "#Type this command, dont copy-paste\n",
        "# Non printing characters inside the command will give totally illogical errors\n",
        "!schematool -initSchema -dbType derby"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metastore connection URL:\t jdbc:derby:;databaseName=metastore_db;create=true\n",
            "Metastore Connection Driver :\t org.apache.derby.jdbc.EmbeddedDriver\n",
            "Metastore connection User:\t APP\n",
            "Starting metastore schema initialization to 3.1.0\n",
            "Initialization script hive-schema-3.1.0.derby.sql\n",
            "\n",
            " \n",
            "Error: FUNCTION 'NUCLEUS_ASCII' already exists. (state=X0Y68,code=30000)\n",
            "org.apache.hadoop.hive.metastore.HiveMetaException: Schema initialization FAILED! Metastore state would be inconsistent !!\n",
            "Underlying cause: java.io.IOException : Schema script failed, errorcode 2\n",
            "Use --verbose for detailed stacktrace.\n",
            "*** schemaTool failed ***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nALF720ewT_-"
      },
      "source": [
        "## 2.6 Test HIVE \n",
        "1. Create database\n",
        "2. Create table\n",
        "3. Insert data\n",
        "4. Retrieve data\n",
        "\n",
        "using command line options as [given here](https://cwiki.apache.org/confluence/display/hive/languagemanual+cli#)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKBG__HrKt9N",
        "outputId": "df1b935b-3211-4c34-8fd9-3aea4cea28f5"
      },
      "source": [
        "!hive -e \"create database if not exists praxisDB;\""
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = 729b0879-46be-4905-a86d-4800c394d2e1\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = d46f927d-da70-410c-b4e4-a3be95688ec4\n",
            "OK\n",
            "Time taken: 1.632 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### command is similar to mysql. it has a compatibility with mysql."
      ],
      "metadata": {
        "id": "YnksOS4r_U47"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thoqjjcHZoLU",
        "outputId": "8f9efe17-1738-4daa-ea41-e0fd70111c7d"
      },
      "source": [
        "!hive -e \"show databases\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = 2f3ca597-bfee-40da-ac6f-78adbd7dcf5e\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 872e5a1b-d4ca-47b8-8d76-febe5d2ef71b\n",
            "OK\n",
            "default\n",
            "praxisdb\n",
            "Time taken: 1.415 seconds, Fetched: 2 row(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duhKRlsnax6U",
        "outputId": "0fb08e7a-0772-487b-cb65-f80b3e65b508"
      },
      "source": [
        "!hive -database praxisdb -e \"create table if not exists emp (name string, age int)\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = ad765ca8-ff21-4411-99a8-83cc53fa1aeb\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = bdd9e618-c3b2-4dba-a854-c1ea506c5395\n",
            "OK\n",
            "Time taken: 1.026 seconds\n",
            "OK\n",
            "Time taken: 1.408 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlXhPGIBbd7v",
        "outputId": "469020a4-a992-435e-d971-a70208aa16c9"
      },
      "source": [
        "!hive -database praxisdb -e \"show tables\""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = 53170e30-d7d9-497e-90e0-b6c100afcbd8\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = a92192f6-7396-45b7-9730-6e0441625956\n",
            "OK\n",
            "Time taken: 1.041 seconds\n",
            "OK\n",
            "emp\n",
            "Time taken: 0.507 seconds, Fetched: 1 row(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### all the commands are taking some time. because each time it is starting hive, starting hadoop, doing the job, and then coming bakc to us. so for small database it is not that meaningful to use hadoop. It becomes significantly important when we have tons of data. "
      ],
      "metadata": {
        "id": "HejVle1JByCD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBbc2fzSb4Po",
        "outputId": "0df2946a-1fdd-4135-d858-41bf04d84e69"
      },
      "source": [
        "!hive -database praxisdb -e \"insert into emp values ('naren', 70)\""
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = ddcf90ee-ee6d-4003-a3a1-4ab9b4f839f1\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = a8688425-0c56-44f4-8161-1c7ed79b0c8a\n",
            "OK\n",
            "Time taken: 1.07 seconds\n",
            "Query ID = root_20221106082556_5dc57231-cc51-4247-9992-0e31710bbff7\n",
            "Total jobs = 3\n",
            "Launching Job 1 out of 3\n",
            "Number of reduce tasks determined at compile time: 1\n",
            "In order to change the average load for a reducer (in bytes):\n",
            "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
            "In order to limit the maximum number of reducers:\n",
            "  set hive.exec.reducers.max=<number>\n",
            "In order to set a constant number of reducers:\n",
            "  set mapreduce.job.reduces=<number>\n",
            "Job running in-process (local Hadoop)\n",
            "2022-11-06 08:26:02,797 Stage-1 map = 100%,  reduce = 100%\n",
            "Ended Job = job_local301679512_0001\n",
            "Stage-4 is selected by condition resolver.\n",
            "Stage-3 is filtered out by condition resolver.\n",
            "Stage-5 is filtered out by condition resolver.\n",
            "Moving data to directory file:/user/hive/warehouse/praxisdb.db/emp/.hive-staging_hive_2022-11-06_08-25-56_496_1077304961128693615-1/-ext-10000\n",
            "Loading data to table praxisdb.emp\n",
            "MapReduce Jobs Launched: \n",
            "Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS\n",
            "Total MapReduce CPU Time Spent: 0 msec\n",
            "OK\n",
            "Time taken: 7.675 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1KvSvdgx7Hc",
        "outputId": "d08da9fe-419e-4de6-b6bb-6addf3ff64a6"
      },
      "source": [
        "!hive -database praxisdb -e \"insert into emp values ('aditya', 49)\""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = 42ac0e15-5342-4f2f-b53a-10850ffb48a4\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = d6f0e718-8853-4e3d-b721-8d1457a0817c\n",
            "OK\n",
            "Time taken: 1.061 seconds\n",
            "Query ID = root_20221106082633_483d3148-74d2-4610-aabf-c3c0a4b484ce\n",
            "Total jobs = 3\n",
            "Launching Job 1 out of 3\n",
            "Number of reduce tasks determined at compile time: 1\n",
            "In order to change the average load for a reducer (in bytes):\n",
            "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
            "In order to limit the maximum number of reducers:\n",
            "  set hive.exec.reducers.max=<number>\n",
            "In order to set a constant number of reducers:\n",
            "  set mapreduce.job.reduces=<number>\n",
            "Job running in-process (local Hadoop)\n",
            "2022-11-06 08:26:39,428 Stage-1 map = 100%,  reduce = 100%\n",
            "Ended Job = job_local673647533_0001\n",
            "Stage-4 is selected by condition resolver.\n",
            "Stage-3 is filtered out by condition resolver.\n",
            "Stage-5 is filtered out by condition resolver.\n",
            "Moving data to directory file:/user/hive/warehouse/praxisdb.db/emp/.hive-staging_hive_2022-11-06_08-26-33_175_1787339677599110892-1/-ext-10000\n",
            "Loading data to table praxisdb.emp\n",
            "MapReduce Jobs Launched: \n",
            "Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS\n",
            "Total MapReduce CPU Time Spent: 0 msec\n",
            "OK\n",
            "Time taken: 7.447 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFxnPRbQclhP",
        "outputId": "104935a7-b8fa-4294-857f-b47a79131ba9"
      },
      "source": [
        "!hive -database praxisdb -e \"select * from emp\""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = 652e8765-5a93-4a75-ac17-17021e6eaee9\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 22f1a485-dbb0-445b-8b7b-7c8148e62533\n",
            "OK\n",
            "Time taken: 1.037 seconds\n",
            "OK\n",
            "naren\t70\n",
            "aditya\t49\n",
            "Time taken: 2.939 seconds, Fetched: 2 row(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Rwm36kUya6A",
        "outputId": "4a6ca3bd-ae76-4a0d-82a6-c07534fc56a2"
      },
      "source": [
        "# Silent Mode\n",
        "!hive -S -database praxisdb -e \"select * from emp\""
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = 25caef69-2361-44b5-b3fb-3a5f2c4546f1\n",
            "Hive Session ID = 22f7a7ae-038e-4435-9541-b0d4a1e28203\n",
            "naren\t70\n",
            "aditya\t49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvIfuSAbkHJ9"
      },
      "source": [
        "## 2.7 Bulk Data Load from CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSFFf3lwkMS0",
        "outputId": "62bf09cd-cee6-44c6-b809-decfd2b85d74"
      },
      "source": [
        "#drop table\n",
        "!hive -database praxisDB -e 'DROP table if exists eCommerce'\n",
        "#create table\n",
        "# Invoice Date is being treated as a STRING because input data is not correctly formatted\n",
        "!hive -database praxisDB -e \" \\\n",
        "CREATE TABLE eCommerce ( \\\n",
        "InvoiceNo varchar(10), \\\n",
        "StockCode varchar(10), \\\n",
        "Description varchar(50), \\\n",
        "Quantity int, \\\n",
        "InvoiceDate string, \\\n",
        "UnitPrice decimal(6,2), \\\n",
        "CustomerID varchar(10), \\\n",
        "Country varchar(15) \\\n",
        ") row format delimited fields terminated by ','; \\\n",
        "\""
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = e8bc46d9-b2b0-4bfe-a695-7101be2aa442\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 24673be6-a289-476b-b6ba-a79f2b88ed44\n",
            "OK\n",
            "Time taken: 1.166 seconds\n",
            "OK\n",
            "Time taken: 0.137 seconds\n",
            "Hive Session ID = 2751b253-510a-438a-aa75-b42cb5a65e2d\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = d921e148-3ba5-47f5-9f78-1f01448ae792\n",
            "OK\n",
            "Time taken: 1.151 seconds\n",
            "OK\n",
            "Time taken: 1.379 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4110Vjf-ktx6",
        "outputId": "ecba9dfe-ba54-44e2-a28f-71633b220457"
      },
      "source": [
        "!hive -database praxisdb -e \"describe eCommerce\""
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = 955e2fce-28de-40ba-b508-a32473fec6ea\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 7a221dbc-5f0a-4aad-8661-80d5c830d401\n",
            "OK\n",
            "Time taken: 1.092 seconds\n",
            "OK\n",
            "invoiceno           \tvarchar(10)         \t                    \n",
            "stockcode           \tvarchar(10)         \t                    \n",
            "description         \tvarchar(50)         \t                    \n",
            "quantity            \tint                 \t                    \n",
            "invoicedate         \tstring              \t                    \n",
            "unitprice           \tdecimal(6,2)        \t                    \n",
            "customerid          \tvarchar(10)         \t                    \n",
            "country             \tvarchar(15)         \t                    \n",
            "Time taken: 0.902 seconds, Fetched: 8 row(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfyabRo5pm7h"
      },
      "source": [
        "This data may not be clean and may have commas embedded in the CSV file. To see how clearn this look at this notebook : [Spark SQLContext HiveContext](https://github.com/prithwis/KKolab/blob/main/KK_C1_SparkSQL_SQLContext_HiveContext.ipynb) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqHKwLOIk67g",
        "outputId": "bf2d04a4-b56a-42c8-e2c2-ebf0eedd712f"
      },
      "source": [
        "#Data as CSV file\n",
        "!gdown https://drive.google.com/uc?id=1JJH24ZZaiJrEKValD--UtyFcWl7UanwV  # 2% data ~ 10K rows\n",
        "!gdown https://drive.google.com/uc?id=1g7mJ0v4fkERW0HWc1eq-SHs_jvQ0N2Oe  # 100% data ~ 500K rows"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JJH24ZZaiJrEKValD--UtyFcWl7UanwV\n",
            "To: /content/eCommerce_02PC_2021.csv\n",
            "100% 917k/917k [00:00<00:00, 98.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1g7mJ0v4fkERW0HWc1eq-SHs_jvQ0N2Oe\n",
            "To: /content/eCommerce_Full_2021.csv\n",
            "100% 45.6M/45.6M [00:00<00:00, 110MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3M5Vl0NlNnQ",
        "outputId": "e68c2650-3f4e-4142-cb50-0a4067d18dbe"
      },
      "source": [
        "#remove the CRLF(Carriage Return,Line Feed) character from the end of the row if it exists\n",
        "!sed 's/\\r//' /content/eCommerce_Full_2021.csv > datafile.csv\n",
        "#!sed 's/\\r//' /content/eCommerce_02PC_2021.csv > datafile.csv\n",
        "# remove the first line containing headers from the file\n",
        "!sed -i -e \"1d\" datafile.csv    \n",
        "!head datafile.csv           "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "536365,85123A,WHITE HANGING HEART T-LIGHT HOLDER,6,12/1/2010 8:26,2.55,17850,United Kingdom\n",
            "536365,71053,WHITE METAL LANTERN,6,12/1/2010 8:26,3.39,17850,United Kingdom\n",
            "536365,84406B,CREAM CUPID HEARTS COAT HANGER,8,12/1/2010 8:26,2.75,17850,United Kingdom\n",
            "536365,84029G,KNITTED UNION FLAG HOT WATER BOTTLE,6,12/1/2010 8:26,3.39,17850,United Kingdom\n",
            "536365,84029E,RED WOOLLY HOTTIE WHITE HEART.,6,12/1/2010 8:26,3.39,17850,United Kingdom\n",
            "536365,22752,SET 7 BABUSHKA NESTING BOXES,2,12/1/2010 8:26,7.65,17850,United Kingdom\n",
            "536365,21730,GLASS STAR FROSTED T-LIGHT HOLDER,6,12/1/2010 8:26,4.25,17850,United Kingdom\n",
            "536366,22633,HAND WARMER UNION JACK,6,12/1/2010 8:28,1.85,17850,United Kingdom\n",
            "536366,22632,HAND WARMER RED POLKA DOT,6,12/1/2010 8:28,1.85,17850,United Kingdom\n",
            "536367,84879,ASSORTED COLOUR BIRD ORNAMENT,32,12/1/2010 8:34,1.69,13047,United Kingdom\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sed means stream editor and it can perform lots of functions on file like searching, find and replace, insertion etc."
      ],
      "metadata": {
        "id": "EatUFYnPFMmF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XljU-WuElcUB",
        "outputId": "6ff4c9a3-2afd-4696-caee-d158a4b679d8"
      },
      "source": [
        "# delete all rows from table\n",
        "!hive -database praxisdb -e 'TRUNCATE TABLE eCommerce'\n",
        "# LOAD\n",
        "!hive -database praxisdb -e \"LOAD DATA LOCAL INPATH 'datafile.csv' INTO TABLE eCommerce\""
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = 1e4da5c6-844a-4e46-b43e-6626b2a0360f\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 18a06fdf-6c6c-4f7d-b8d5-c530b1baaa84\n",
            "OK\n",
            "Time taken: 1.025 seconds\n",
            "OK\n",
            "Time taken: 1.362 seconds\n",
            "Hive Session ID = b1a2b02c-b03a-42ef-aaed-c03ed459d113\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = e724be08-571a-4023-8a27-9d817daf8ef2\n",
            "OK\n",
            "Time taken: 1.081 seconds\n",
            "Loading data to table praxisdb.ecommerce\n",
            "OK\n",
            "Time taken: 2.264 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRceNDPylu2U",
        "outputId": "538add74-33fa-44ff-f63b-5a57bd353f01"
      },
      "source": [
        "!hive -S -database praxisdb -e \"select count(*) from eCommerce\""
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = c89856e1-592b-408c-bba5-08d3c8536e19\n",
            "Hive Session ID = b7e37601-3649-44d9-a12b-9ed642ffb726\n",
            "541909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m977A2Jnl5mZ",
        "outputId": "67ed9597-dbe5-4e94-fd31-f55f7ffdc011"
      },
      "source": [
        "!hive -S -database praxisdb -e \"select * from eCommerce limit 30\""
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = 23bf981f-da93-4f2a-9905-5b942e8b4d8f\n",
            "Hive Session ID = 589b78d2-08d9-4eda-abb2-26c671c76781\n",
            "536365\t85123A\tWHITE HANGING HEART T-LIGHT HOLDER\t6\t12/1/2010 8:26\t2.55\t17850\tUnited Kingdom\n",
            "536365\t71053\tWHITE METAL LANTERN\t6\t12/1/2010 8:26\t3.39\t17850\tUnited Kingdom\n",
            "536365\t84406B\tCREAM CUPID HEARTS COAT HANGER\t8\t12/1/2010 8:26\t2.75\t17850\tUnited Kingdom\n",
            "536365\t84029G\tKNITTED UNION FLAG HOT WATER BOTTLE\t6\t12/1/2010 8:26\t3.39\t17850\tUnited Kingdom\n",
            "536365\t84029E\tRED WOOLLY HOTTIE WHITE HEART.\t6\t12/1/2010 8:26\t3.39\t17850\tUnited Kingdom\n",
            "536365\t22752\tSET 7 BABUSHKA NESTING BOXES\t2\t12/1/2010 8:26\t7.65\t17850\tUnited Kingdom\n",
            "536365\t21730\tGLASS STAR FROSTED T-LIGHT HOLDER\t6\t12/1/2010 8:26\t4.25\t17850\tUnited Kingdom\n",
            "536366\t22633\tHAND WARMER UNION JACK\t6\t12/1/2010 8:28\t1.85\t17850\tUnited Kingdom\n",
            "536366\t22632\tHAND WARMER RED POLKA DOT\t6\t12/1/2010 8:28\t1.85\t17850\tUnited Kingdom\n",
            "536367\t84879\tASSORTED COLOUR BIRD ORNAMENT\t32\t12/1/2010 8:34\t1.69\t13047\tUnited Kingdom\n",
            "536367\t22745\tPOPPY'S PLAYHOUSE BEDROOM \t6\t12/1/2010 8:34\t2.10\t13047\tUnited Kingdom\n",
            "536367\t22748\tPOPPY'S PLAYHOUSE KITCHEN\t6\t12/1/2010 8:34\t2.10\t13047\tUnited Kingdom\n",
            "536367\t22749\tFELTCRAFT PRINCESS CHARLOTTE DOLL\t8\t12/1/2010 8:34\t3.75\t13047\tUnited Kingdom\n",
            "536367\t22310\tIVORY KNITTED MUG COSY \t6\t12/1/2010 8:34\t1.65\t13047\tUnited Kingdom\n",
            "536367\t84969\tBOX OF 6 ASSORTED COLOUR TEASPOONS\t6\t12/1/2010 8:34\t4.25\t13047\tUnited Kingdom\n",
            "536367\t22623\tBOX OF VINTAGE JIGSAW BLOCKS \t3\t12/1/2010 8:34\t4.95\t13047\tUnited Kingdom\n",
            "536367\t22622\tBOX OF VINTAGE ALPHABET BLOCKS\t2\t12/1/2010 8:34\t9.95\t13047\tUnited Kingdom\n",
            "536367\t21754\tHOME BUILDING BLOCK WORD\t3\t12/1/2010 8:34\t5.95\t13047\tUnited Kingdom\n",
            "536367\t21755\tLOVE BUILDING BLOCK WORD\t3\t12/1/2010 8:34\t5.95\t13047\tUnited Kingdom\n",
            "536367\t21777\tRECIPE BOX WITH METAL HEART\t4\t12/1/2010 8:34\t7.95\t13047\tUnited Kingdom\n",
            "536367\t48187\tDOORMAT NEW ENGLAND\t4\t12/1/2010 8:34\t7.95\t13047\tUnited Kingdom\n",
            "536368\t22960\tJAM MAKING SET WITH JARS\t6\t12/1/2010 8:34\t4.25\t13047\tUnited Kingdom\n",
            "536368\t22913\tRED COAT RACK PARIS FASHION\t3\t12/1/2010 8:34\t4.95\t13047\tUnited Kingdom\n",
            "536368\t22912\tYELLOW COAT RACK PARIS FASHION\t3\t12/1/2010 8:34\t4.95\t13047\tUnited Kingdom\n",
            "536368\t22914\tBLUE COAT RACK PARIS FASHION\t3\t12/1/2010 8:34\t4.95\t13047\tUnited Kingdom\n",
            "536369\t21756\tBATH BUILDING BLOCK WORD\t3\t12/1/2010 8:35\t5.95\t13047\tUnited Kingdom\n",
            "536370\t22728\tALARM CLOCK BAKELIKE PINK\t24\t12/1/2010 8:45\t3.75\t12583\tFrance\n",
            "536370\t22727\tALARM CLOCK BAKELIKE RED \t24\t12/1/2010 8:45\t3.75\t12583\tFrance\n",
            "536370\t22726\tALARM CLOCK BAKELIKE GREEN\t12\t12/1/2010 8:45\t3.75\t12583\tFrance\n",
            "536370\t21724\tPANDA AND BUNNIES STICKER SHEET\t12\t12/1/2010 8:45\t0.85\t12583\tFrance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!hive -S -database praxisdb -e \"select * from eCommerce where country = 'France' limit 30\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-CRY2kbGmCu",
        "outputId": "e6d114a5-d2e2-4945-d359-88617e8a8fbb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = 471121c6-79c0-439e-b4cb-fc14be6abdc0\n",
            "Hive Session ID = 9151a73d-4268-4e92-8735-ad2eb5810347\n",
            "536370\t22728\tALARM CLOCK BAKELIKE PINK\t24\t12/1/2010 8:45\t3.75\t12583\tFrance\n",
            "536370\t22727\tALARM CLOCK BAKELIKE RED \t24\t12/1/2010 8:45\t3.75\t12583\tFrance\n",
            "536370\t22726\tALARM CLOCK BAKELIKE GREEN\t12\t12/1/2010 8:45\t3.75\t12583\tFrance\n",
            "536370\t21724\tPANDA AND BUNNIES STICKER SHEET\t12\t12/1/2010 8:45\t0.85\t12583\tFrance\n",
            "536370\t21883\tSTARS GIFT TAPE \t24\t12/1/2010 8:45\t0.65\t12583\tFrance\n",
            "536370\t10002\tINFLATABLE POLITICAL GLOBE \t48\t12/1/2010 8:45\t0.85\t12583\tFrance\n",
            "536370\t21791\tVINTAGE HEADS AND TAILS CARD GAME \t24\t12/1/2010 8:45\t1.25\t12583\tFrance\n",
            "536370\t21035\tSET/2 RED RETROSPOT TEA TOWELS \t18\t12/1/2010 8:45\t2.95\t12583\tFrance\n",
            "536370\t22326\tROUND SNACK BOXES SET OF4 WOODLAND \t24\t12/1/2010 8:45\t2.95\t12583\tFrance\n",
            "536370\t22629\tSPACEBOY LUNCH BOX \t24\t12/1/2010 8:45\t1.95\t12583\tFrance\n",
            "536370\t22659\tLUNCH BOX I LOVE LONDON\t24\t12/1/2010 8:45\t1.95\t12583\tFrance\n",
            "536370\t22631\tCIRCUS PARADE LUNCH BOX \t24\t12/1/2010 8:45\t1.95\t12583\tFrance\n",
            "536370\t22661\tCHARLOTTE BAG DOLLY GIRL DESIGN\t20\t12/1/2010 8:45\t0.85\t12583\tFrance\n",
            "536370\t21731\tRED TOADSTOOL LED NIGHT LIGHT\t24\t12/1/2010 8:45\t1.65\t12583\tFrance\n",
            "536370\t22900\t SET 2 TEA TOWELS I LOVE LONDON \t24\t12/1/2010 8:45\t2.95\t12583\tFrance\n",
            "536370\t21913\tVINTAGE SEASIDE JIGSAW PUZZLES\t12\t12/1/2010 8:45\t3.75\t12583\tFrance\n",
            "536370\t22540\tMINI JIGSAW CIRCUS PARADE \t24\t12/1/2010 8:45\t0.42\t12583\tFrance\n",
            "536370\t22544\tMINI JIGSAW SPACEBOY\t24\t12/1/2010 8:45\t0.42\t12583\tFrance\n",
            "536370\t22492\tMINI PAINT SET VINTAGE \t36\t12/1/2010 8:45\t0.65\t12583\tFrance\n",
            "536370\tPOST\tPOSTAGE\t3\t12/1/2010 8:45\t18.00\t12583\tFrance\n",
            "536852\t22549\tPICTURE DOMINOES\t12\t12/3/2010 9:51\t1.45\t12686\tFrance\n",
            "536852\t22544\tMINI JIGSAW SPACEBOY\t24\t12/3/2010 9:51\t0.42\t12686\tFrance\n",
            "536852\t22539\tMINI JIGSAW DOLLY GIRL\t24\t12/3/2010 9:51\t0.42\t12686\tFrance\n",
            "536852\t22661\tCHARLOTTE BAG DOLLY GIRL DESIGN\t10\t12/3/2010 9:51\t0.85\t12686\tFrance\n",
            "536852\t21791\tVINTAGE HEADS AND TAILS CARD GAME \t12\t12/3/2010 9:51\t1.25\t12686\tFrance\n",
            "536852\t21786\tPOLKADOT RAIN HAT \t24\t12/3/2010 9:51\t0.42\t12686\tFrance\n",
            "536852\tPOST\tPOSTAGE\t1\t12/3/2010 9:51\t18.00\t12686\tFrance\n",
            "536974\t15056BL\tEDWARDIAN PARASOL BLACK\t9\t12/3/2010 13:59\t5.95\t12682\tFrance\n",
            "536974\t15056P\tEDWARDIAN PARASOL PINK\t3\t12/3/2010 13:59\t5.95\t12682\tFrance\n",
            "536974\t20679\tEDWARDIAN PARASOL RED\t6\t12/3/2010 13:59\t5.95\t12682\tFrance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "print('signed off at  ',datetime.now(pytz.timezone('Asia/Kolkata')))"
      ],
      "metadata": {
        "id": "-CtmCPvi4jJ1",
        "outputId": "699ff288-1905-46ea-dd90-7035418bb9e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "signed off at   2022-10-07 10:58:20.965135+05:30\n"
          ]
        }
      ]
    }
  ]
}